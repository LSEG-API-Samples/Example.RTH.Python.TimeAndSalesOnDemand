{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tick History Time And Sales\n",
    "This sample demonstrates how to get the list of Tick History Time And Sales fields, request data according to the selected fields and display data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "- Python 3.6 or higher\n",
    "- Jupyter Notebook\n",
    "- DSS user account which can access Tick History Time And Sales. Tick History is hosted on DSS(DataScope Select platform). Please contact Refinitiv account team to get the user.\n",
    "\n",
    "## Implementation\n",
    "### Step 1. Request authentication token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Import required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass as gp\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import copy\n",
    "import time\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Input DSS username and password"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "username=input('Enter DSS username:')\n",
    "password=gp.getpass('Enter DSS Password:')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Create authentication token request containing DSS username and password"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "requestUrl = \"https://hosted.datascopeapi.reuters.com/RestApi/v1/Authentication/RequestToken\"\n",
    "requestHeaders={\n",
    "    \"Prefer\":\"respond-async\",\n",
    "    \"Content-Type\":\"application/json\"\n",
    "    }\n",
    "requestBody={\n",
    "    \"Credentials\": {\n",
    "    \"Username\": username,\n",
    "    \"Password\": password\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- send the request and waits for the response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "authenticationResp = requests.post(requestUrl, json=requestBody,headers=requestHeaders)\n",
    "print(\"Received the response for authentication request\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Check if the status code of the response is 200. If yes, the request has succeeded so extracts and prints the authentication token. Otherwise, print the error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if authenticationResp.status_code == 200 :\n",
    "    print(\"Received status code 200, get the authentication token from the response\")\n",
    "    jsonResponse = json.loads(authenticationResp.text.encode('ascii', 'ignore'))\n",
    "    token = jsonResponse[\"value\"]\n",
    "    print ('Authentication token (valid 24 hours):')\n",
    "    print (token)\n",
    "else:\n",
    "    print(\"Error with status code:\",authenticationResp.status_code,\"\\n Text:\",json.dumps(json.loads(authenticationResp.text),indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2. Retrieve the list of available fields.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- create a  Time and Sales content field types request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "requestUrl='https://hosted.datascopeapi.reuters.com/RestApi/v1/Extractions/GetValidContentFieldTypes(ReportTemplateType=ThomsonReuters.Dss.Api.Extractions.ReportTemplates.ReportTemplateTypes\\'TickHistoryTimeAndSales\\')'\n",
    "requestHeaders={\n",
    "    \"Prefer\":\"respond-async\",\n",
    "    \"Authorization\": \"token \" + token\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- send the request and waits for the response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contentFieldTypesResp = requests.get(requestUrl, headers=requestHeaders)\n",
    "print(\"Received the response for content field types request\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Check if the status code of the response is 200. If yes, the request has succeeded so keep the field types. Otherwise, print the error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contentFieldTypesJson = None\n",
    "if contentFieldTypesResp.status_code == 200 :\n",
    "    print(\"Received status code 200, requested for content field types successfully\")\n",
    "    contentFieldTypesJson = json.loads(contentFieldTypesResp.text.encode('ascii', 'ignore'))\n",
    "    wholeContentFieldTypes = contentFieldTypesJson[\"value\"]\n",
    "else:\n",
    "    print(\"Error with status code:\",contentFieldTypesResp.status_code,\"\\n Text:\",json.dumps(json.loads(contentFieldTypesResp.text),indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Print the fields type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The Content Fields Types Table\")\n",
    "df = pd.DataFrame(wholeContentFieldTypes, columns=[\"Name\", \"Description\",\"FormatType\"])\n",
    "pd.set_option('display.max_rows', df.shape[0]+1)\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "df.index += 1\n",
    "dfStyler=df.style.set_properties(**{'text-align': 'left'})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3. Send Time And Sales On demand Extraction Request\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Input the Identifiers and their Identifier types. For the valid Identifier types, please refer to \n",
    "[REST API Reference Tree](https://hosted.datascopeapi.reuters.com/RestApi.Help/Home/RestApiProgrammingSdk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indentifierDict={}\n",
    "InstrumentIdentifiersList = []\n",
    "anIndentifier=input(\"Enter an identifier with its type e.g.IBM.N,Ric (press enter to exit):\")\n",
    "while len(anIndentifier) > 0:\n",
    "    anIndentifierType=anIndentifier.split(\",\")\n",
    "    if(len(anIndentifierType)) >= 2:\n",
    "        indentifierDict[\"Identifier\"]=anIndentifierType[0]\n",
    "        indentifierDict[\"IdentifierType\"]=anIndentifierType[1]\n",
    "        InstrumentIdentifiersList.append(indentifierDict.copy())\n",
    "    anIndentifier=input(\"Enter an identifier with its type e.g. (press enter to exit):\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Select content fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalFields = len(wholeContentFieldTypes)\n",
    "selectedFields = []\n",
    "print(\"Please see the Content Fields Types table above\")\n",
    "requestFields=input(\"Enter the fields index(1-\" + str(totalFields) + \") separated by ','  :\")\n",
    "requestFieldsList=requestFields.split(\",\")\n",
    "for aFidNum in requestFieldsList:\n",
    "    if int(aFidNum) < 1 or int(aFidNum) > totalFields:\n",
    "        print(\"Invalid fields index \" + str(aFidNum) + \",skip this.\");\n",
    "    else:\n",
    "        selectedFields.append(wholeContentFieldTypes[int(aFidNum)-1][\"Name\"])\n",
    "print()\n",
    "print(\"The selected fields are:\")\n",
    "for aField in selectedFields:\n",
    "    print(aField)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create an on demand extracton for Time And Sales. For the parameters of each request, please refer to \n",
    "[REST API Reference Tree](https://hosted.datascopeapi.reuters.com/RestApi.Help/Home/RestApiProgrammingSdk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    - Create request url and headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "requestUrl='https://hosted.datascopeapi.reuters.com/RestApi/v1/Extractions/ExtractRaw'\n",
    "requestHeaders={\n",
    "    \"Prefer\":\"respond-async\",\n",
    "    \"Content-Type\":\"application/json\",\n",
    "    \"Authorization\": \"token \" + token\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    - Create request body containing input identifiers and content field types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "requestBody={\n",
    "  \"ExtractionRequest\": {\n",
    "    \"@odata.type\": \"#ThomsonReuters.Dss.Api.Extractions.ExtractionRequests.TickHistoryTimeAndSalesExtractionRequest\",\n",
    "    \"ContentFieldNames\": selectedFields,\n",
    "    \"IdentifierList\": {\n",
    "      \"@odata.type\": \"#ThomsonReuters.Dss.Api.Extractions.ExtractionRequests.InstrumentIdentifierList\",  \n",
    "      \"InstrumentIdentifiers\": InstrumentIdentifiersList,\n",
    "       \"UseUserPreferencesForValidationOptions\": \"false\"\n",
    "    },  \n",
    "    \"Condition\": {\n",
    "       \"MessageTimeStampIn\": \"GmtUtc\",\n",
    "        \"ApplyCorrectionsAndCancellations\": \"false\",\n",
    "        \"ReportDateRangeType\": \"Range\",\n",
    "        \"QueryStartDate\": \"2019-11-06T00:00:00.000Z\",\n",
    "        \"QueryEndDate\": \"2019-11-06T23:59:59.999Z\",\n",
    "        \"DisplaySourceRIC\": \"false\"\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- send the request and waits for the response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractionResp = requests.post(requestUrl, json=requestBody,headers=requestHeaders)\n",
    "print(\"Received the response for on demand extraction request\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4. Check the request status untill the request has been processed completely.\n",
    "\n",
    "- If the HTTP status code of response is 202 this means the extraction request was accepted, but processing has not completed yet. Hence, the application gets the received location url from 202 response header received in the previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "requestStatus =  extractionResp.status_code\n",
    "print(\"Received status code \" + str(requestStatus))\n",
    "requestUrl=None\n",
    "if requestStatus == 202 :\n",
    "    requestUrl = extractionResp.headers[\"location\"]\n",
    "    print ('Extraction is not complete, poll the location URL:')\n",
    "    print (str(requestUrl))\n",
    "else:\n",
    "    print(\"Error with status code:\",requestStatus,\"\\n Text:\",json.dumps(json.loads(extractionResp.text),indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- While the status of the request is 202, poll the request status every 30 seconds using the location url got from the previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while (requestStatus == 202):\n",
    "    print ('Received status code 202, waits 30 seconds, then poll again until the status is not 202')\n",
    "    time.sleep(30)\n",
    "    extractionResp = requests.get(requestUrl,headers=requestHeaders)\n",
    "    requestStatus= extractionResp.status_code\n",
    "print ('Received status code which is not 202')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- When the request is completed (The HTTP status code is not 202), check the status code. If it is 200 or OK, the application gets and prints the results which are jobId and the extraction notes. The jobId is used to retrieve the data while the extraction can be used to analyze data or troubleshooting problems. Apart from the HTTP status code 200, it is an error and prints the error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if requestStatus == 200 :\n",
    "    print(\"Received status code 200, get the JobId and Extraction notes\")\n",
    "    extractionRespJson = json.loads(extractionResp.text.encode('ascii', 'ignore'))\n",
    "    jobId = extractionRespJson[\"JobId\"]\n",
    "    print ('\\njobId: ' + jobId + '\\n')\n",
    "    notes = extractionRespJson[\"Notes\"]\n",
    "    print ('Extraction notes:\\n' + notes[0])\n",
    "else:\n",
    "    print(\"Error with status code:\",extractionResp.status_code,\"\\n Text:\",json.dumps(json.loads(extractionResp.text),indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4. Retrieve data from TRTH or AWS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Send HTTP get with a JobID got from the 200 OK response to retrieve data from TRTH or AWS. TRTH provides downloading some extraction data directly from Amazon Web Services (AWS) where the data files are hosted. The tick history data types which are supported by this feature are:\n",
    "    * Time and Sales\n",
    "    * Market Depth\n",
    "    * Intraday Summaries\n",
    "    * Raw.\n",
    "    \n",
    "  This sample requests for Time and Sales which supports AWS download.  Therefore, I will download data from AWS which provides faster download speed than TRTH directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DownloadFromAWS=True\n",
    "requestUrl=\"https://hosted.datascopeapi.reuters.com/RestApi/v1/Extractions/RawExtractionResults\" + \"('\" + jobId + \"')\" + \"/$value\"\n",
    "requestHeaders={\n",
    "        \"Prefer\":\"respond-async\",\n",
    "        \"Content-Type\":\"text/plain\",\n",
    "        \"Accept-Encoding\":\"gzip\",\n",
    "        \"Authorization\": \"token \" + token\n",
    "}\n",
    "if DownloadFromAWS==True:\n",
    "    requestHeaders.update({\"X-Direct-Download\":\"true\"})\n",
    "dataRetrieveResp=requests.get(requestUrl,headers=requestHeaders,stream=True)\n",
    "print(\"Received the response for retreiving data using the jobId\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If the status is 200 or OK that means the application can retrieve data from TRTH or AWS successfully. Otherwise, print the error and exits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataRetrieveResp.status_code == 200 :\n",
    "    print(\"Received status code 200, retrieved data from the server successfully\")\n",
    "else:\n",
    "    print(\"Error with status code:\",extractionResp.status_code,\"\\n Text:\",json.dumps(json.loads(extractionResp.text),indent=4))\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- save the downloaded data before decompressing it instead of decompressing it on the fly. This is to avoid data lost issues especially with large data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "dataRetrieveResp.raw.decode_content = False\n",
    "fileName= os.getcwd() + \"\\compressData.csv.gz\" \n",
    "print ('Saving compressed data to file:' + fileName + ' ... please be patient')\n",
    "\n",
    "chunk_size = 1024\n",
    "rr = dataRetrieveResp.raw\n",
    "with open(fileName, 'wb') as fd:\n",
    "    shutil.copyfileobj(rr, fd, chunk_size)\n",
    "fd.close\n",
    "\n",
    "print ('Finished saving compressed data to file:' + fileName + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For the best practice, you should handle the data line by line instead of store all the data in one variable. This is to avoid issues with large data sets. Below is the code to read and decompress for each line (maximum 15 lines) from the data file that just created and display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "maxLine=15\n",
    "print ('Reading data from file, and decompress at most ' + str(maxLine) + ' lines of it:')\n",
    "count = 0\n",
    "with gzip.open(fileName, 'rb') as fd:\n",
    "    for line in fd:\n",
    "        dataLine = line.decode(\"utf-8\")\n",
    "        print (dataLine)\n",
    "        count += 1\n",
    "        if count > maxLine:\n",
    "            break\n",
    "fd.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
